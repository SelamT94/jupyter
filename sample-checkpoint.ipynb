{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "57998c79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import string\n",
    "import os\n",
    "import re\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "587b41aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LoadData:\n",
    "  def __init__(self,directory_name,file_name):\n",
    "    self.directory_name=directory_name\n",
    "    self.file_name = file_name\n",
    "    \n",
    "  def read_file(self):\n",
    "    os.chdir(self.directory_name)\n",
    "    tweets_df=pd.read_file(self.file_name)\n",
    "    return tweets_df\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3b4c4b4c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'drive' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mdrive\u001b[49m\u001b[38;5;241m.\u001b[39mmount(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive\u001b[39m\u001b[38;5;124m\"\u001b[39m, force_remount\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m      2\u001b[0m LoadData_obj\u001b[38;5;241m=\u001b[39m LoadData(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdrive/MyDrive\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcleaned_fintech_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'drive' is not defined"
     ]
    }
   ],
   "source": [
    "drive.mount(\"/content/drive\", force_remount=True)\n",
    "LoadData_obj= LoadData('drive/MyDrive','cleaned_fintech_data.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3aca1c6a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'drive/MyDrive'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tweets_df\u001b[38;5;241m=\u001b[39m\u001b[43mLoadData_obj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m tweets_df\u001b[38;5;241m.\u001b[39mdropna()\n",
      "Input \u001b[1;32mIn [2]\u001b[0m, in \u001b[0;36mLoadData.read_file\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mread_file\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m----> 7\u001b[0m   \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdirectory_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m   tweets_df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mread_file(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_name)\n\u001b[0;32m      9\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tweets_df\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'drive/MyDrive'"
     ]
    }
   ],
   "source": [
    "tweets_df=LoadData_obj.read_file()\n",
    "tweets_df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81da7a0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tweets_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28mlen\u001b[39m(\u001b[43mtweets_df\u001b[49m)\n\u001b[0;32m      2\u001b[0m tweets_df\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tweets_df' is not defined"
     ]
    }
   ],
   "source": [
    "len(tweets_df)\n",
    "tweets_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f3c56141",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PrepareData:\n",
    "  def __init__(self,df):\n",
    "    self.df=df\n",
    "    \n",
    "  def preprocess_data(self):\n",
    "    tweets_df = self.df.loc[self.df['lang'] ==\"en\"]\n",
    "\n",
    "    \n",
    "    #text Preprocessing\n",
    "    tweets_df['clean_text']=tweets_df['clean_text'].astype(str)\n",
    "    tweets_df['clean_text'] = tweets_df['clean_text'].apply(lambda x: x.lower())\n",
    "    tweets_df['clean_text']= tweets_df['clean_text'].apply(lambda x: x.translate(str.maketrans(' ', ' ', string.punctuation)))\n",
    "    \n",
    "    #Converting tweets to list of words For feature engineering\n",
    "    sentence_list = [tweet for tweet in tweets_df['clean_text']]\n",
    "    word_list = [sent.split() for sent in sentence_list]\n",
    "    # print(word_list)\n",
    "\n",
    "    #Create dictionary which contains Id and word \n",
    "    word_to_id = corpora.Dictionary(word_list) #generate unique tokens\n",
    "    #  we can see the word to unique integer mapping\n",
    "    # print(word_to_id.token2id)\n",
    "    # using bag of words(bow), we create a corpus that contains the word id and its frequency in each document.\n",
    "    corpus_1= [word_to_id.doc2bow(tweet) for tweet in word_list]\n",
    "    # TFIDF\n",
    "\n",
    "    return word_list, word_to_id, corpus_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc708a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "PrepareData_obj=PrepareData(tweets_df)\n",
    "word_list ,id2word,corpus=PrepareData_obj.preprocess_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e0bd4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6a26425",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_words = [[(id2word[id], count) for id, count in line] for line in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0c2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(id_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
